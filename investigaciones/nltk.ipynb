{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://user-images.githubusercontent.com/14845203/190489800-59a8b8c6-353f-4537-bb7e-0c0a63ef1109.png\" alt=\"JuveYell\" width=\"250px\">\n",
    "\n",
    "### Facultad de Ingeniería Mecánica y Eléctrica\n",
    "### Procesamiento de Lenguaje Natural\n",
    "### Carrillo Zepeda Oswaldo\n",
    "### Braulio Yahir Gaitan Vargas\n",
    "### 6°D\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funciones de la librería de procesamiento de lenguaje natural de Python, NLTK.\n",
    "Todas las funciones que no llegamos a usar en el proyecto, pero que son interesantes de mencionar.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funcion nltk.classify\n",
    "La función `nltk.classify.accuracy` calcula la precisión de un clasificador. Recibe dos argumentos, el clasificador y el conjunto de datos de prueba. Devuelve la precisión del clasificador en el conjunto de datos de prueba.\n",
    "\n",
    "```python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     C:\\Users\\pabli\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del clasificador: 0.75\n",
      "Clasificación de la nueva crítica: neg\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import movie_reviews\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.classify.util import accuracy\n",
    "\n",
    "\n",
    "# Obtén las palabras más frecuentes y sus categorías (positivo/negativo)\n",
    "documents = [(list(movie_reviews.words(fileid)), category)\n",
    "             for category in movie_reviews.categories()\n",
    "             for fileid in movie_reviews.fileids(category)]\n",
    "\n",
    "# Mezcla los documentos para que no estén ordenados por categoría\n",
    "import random\n",
    "random.shuffle(documents)\n",
    "\n",
    "# Extrae las palabras de todos los documentos\n",
    "all_words = nltk.FreqDist(w.lower() for w in movie_reviews.words())\n",
    "\n",
    "# Selecciona las 2000 palabras más frecuentes como características\n",
    "word_features = list(all_words)[:2000]\n",
    "\n",
    "# Define una función para extraer características de un documento\n",
    "def document_features(document):\n",
    "    document_words = set(document)\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features['contains({})'.format(word)] = (word in document_words)\n",
    "    return features\n",
    "\n",
    "# Extrae características y crea conjuntos de entrenamiento y prueba\n",
    "featuresets = [(document_features(d), c) for (d,c) in documents]\n",
    "train_set, test_set = featuresets[100:], featuresets[:100]\n",
    "\n",
    "# Entrena un clasificador de Naive Bayes\n",
    "classifier = NaiveBayesClassifier.train(train_set)\n",
    "\n",
    "# Evalúa la precisión del clasificador\n",
    "print(\"Precisión del clasificador:\", accuracy(classifier, test_set))\n",
    "\n",
    "# Prueba el clasificador con nuevas críticas\n",
    "new_review = \"This movie was excellent. I loved every moment of it.\"\n",
    "new_review_features = document_features(word_tokenize(new_review))\n",
    "print(\"Clasificación de la nueva crítica:\", classifier.classify(new_review_features))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nltk corpus es una funcion para obtener un corpus de nltk "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S (NP the/DT big/JJ dog/NN))\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.chunk import RegexpParser\n",
    "\n",
    "# Define a chunk grammar, a set of rules to find chunks in text\n",
    "grammar = \"NP: {<DT>?<JJ>*<NN>}\"\n",
    "\n",
    "# Create a chunk parser with the grammar\n",
    "cp = RegexpParser(grammar)\n",
    "\n",
    "# Parse a sentence into chunks\n",
    "sentence = [(\"the\", \"DT\"), (\"big\", \"JJ\"), (\"dog\", \"NN\")]\n",
    "print(cp.parse(sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nltk.grammar proporciona clases y funciones para trabajar con gramáticas formales. Estas gramáticas pueden ser de diferentes tipos, como gramáticas de contexto libre (CFG), gramáticas de dependencias, entre otras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S (NP the (N cat)) (VP (V chased) (NP the (N dog))))\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import CFG\n",
    "\n",
    "# Define a context-free grammar\n",
    "grammar = CFG.fromstring(\"\"\"\n",
    "    S -> NP VP\n",
    "    PP -> P NP\n",
    "    NP -> 'the' N | N PP | 'the' N PP\n",
    "    VP -> V NP | V PP | V NP PP\n",
    "    N -> 'cat' | 'dog' | 'rug'\n",
    "    V -> 'chased' | 'sat'\n",
    "    P -> 'on' | 'in'\n",
    "\"\"\")\n",
    "\n",
    "# Create a parser with the grammar\n",
    "parser = nltk.ChartParser(grammar)\n",
    "\n",
    "# Parse a sentence\n",
    "sentence = \"the cat chased the dog\".split()\n",
    "for tree in parser.parse(sentence):\n",
    "    print(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nltk metrics proporciona funciones para calcular métricas de evaluación de clasificadores y otros modelos de aprendizaje automático."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F-measure: 1.0\n",
      "Accuracy: 0.5\n",
      "Confusion matrix:\n",
      "      |   s |\n",
      "     | h p |\n",
      "     | a a |\n",
      "     | m m |\n",
      "-----+-----+\n",
      " ham |<1>2 |\n",
      "spam | 1<2>|\n",
      "-----+-----+\n",
      "(row = reference; col = test)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nltk.metrics import precision, recall, f_measure\n",
    "from nltk.metrics.scores import accuracy\n",
    "from nltk import ConfusionMatrix\n",
    "\n",
    "# True labels and predicted labels\n",
    "true_labels = ['spam', 'ham', 'spam', 'spam', 'ham', 'ham']\n",
    "predicted_labels = ['spam', 'spam', 'spam', 'ham', 'ham', 'spam']\n",
    "\n",
    "# Create a confusion matrix\n",
    "cm = ConfusionMatrix(true_labels, predicted_labels)\n",
    "\n",
    "# Calculate precision, recall, and F-measure for 'spam'\n",
    "print(\"Precision:\", precision(set(true_labels), set(predicted_labels)))\n",
    "print(\"Recall:\", recall(set(true_labels), set(predicted_labels)))\n",
    "print(\"F-measure:\", f_measure(set(true_labels), set(predicted_labels)))\n",
    "\n",
    "# Calculate accuracy\n",
    "print(\"Accuracy:\", accuracy(true_labels, predicted_labels))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion matrix:\\n\", cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nltk.misc.wordfinder: Ofrece una función para buscar palabras que coincidan con un patrón dado dentro de un archivo de texto. Es útil para buscar palabras específicas o patrones de palabras en grandes cantidades de texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import words\n",
    "from nltk.misc import wordfinder\n",
    "\n",
    "# Get a list of all English words\n",
    "word_list = words.words()\n",
    "\n",
    "# Find all words that start with 'a' and end with 'm'\n",
    "pattern = 'a*m'\n",
    "matching_words = wordfinder.words(word_list, pattern)\n",
    "\n",
    "# Print the matching words\n",
    "for word in matching_words:\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RecursiveDescentParser proceso de analizar la estructura sintáctica de una oración o un conjunto de palabras de acuerdo con una gramática específica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import CFG\n",
    "from nltk.parse import RecursiveDescentParser\n",
    "\n",
    "# Define a context-free grammar\n",
    "grammar = CFG.fromstring(\"\"\"\n",
    "    S -> NP VP\n",
    "    NP -> Det N | Det N PP\n",
    "    VP -> V NP | VP PP\n",
    "    PP -> P NP\n",
    "    Det -> 'a' | 'the'\n",
    "    N -> 'dog' | 'cat'\n",
    "    V -> 'chased' | 'sat'\n",
    "    P -> 'on' | 'in'\n",
    "\"\"\")\n",
    "\n",
    "# Create a parser with the grammar\n",
    "rd_parser = RecursiveDescentParser(grammar)\n",
    "\n",
    "# Parse a sentence\n",
    "sentence = \"the dog chased a cat\".split()\n",
    "for tree in rd_parser.parse(sentence):\n",
    "    print(tree)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
